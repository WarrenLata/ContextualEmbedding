{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q of shape (Batch size, sequence_len)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dk, dv, d_model,attention_probs_dropout_prob,device='cpu'):\n",
    "        super().__init__()\n",
    "        self.WQ = nn.Linear(d_model,dk, device = device)\n",
    "        self.WK = nn.Linear(d_model,dk, device = device)\n",
    "        self.WV = nn.Linear(d_model,dv, device = device)\n",
    "        self.dk = dk\n",
    "        self.dropout = nn.Dropout(attention_probs_dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v ):\n",
    "        q = self.WQ(q)\n",
    "        k = self.WK(k)\n",
    "        v = self.WV(v)\n",
    "        attention_scores  = F.softmax(torch.matmul(q,k.transpose(1,2))/np.sqrt(self.dk),dim=-1)\n",
    "        \n",
    "        attention_matrix  = torch.matmul(attention_scores, v)\n",
    "\n",
    "        return self.dropout(attention_matrix)\n",
    "    \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, dk, dv, d_model,attention_probs_dropout_prob, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.attentions = nn.ModuleList([Attention(dk,dv, d_model,attention_probs_dropout_prob, device) for _ in range(n_head)])\n",
    "\n",
    "        self.output = nn.Linear(n_head*dv, d_model, device = device )\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "\n",
    "        attention_matrices = [attention(q,k,v) for attention in self.attentions]\n",
    "\n",
    "        attentions = torch.cat(attention_matrices, dim=-1)\n",
    "\n",
    "        return self.output(attentions)\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden_dim,hidden_dropout_prob, device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.ff2 = nn.Linear(hidden_dim, d_model, device = device)\n",
    "        self.ff1 = nn.Linear(d_model, hidden_dim, device = device)\n",
    "        self.GELU = nn.GELU()\n",
    "        self.dropout = nn.Dropout(hidden_dropout_prob)  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ff1(x)\n",
    "        x = self.GELU(x)\n",
    "        x = self.ff2(x)\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "class BERTLayer(nn.Module):\n",
    "    def __init__(self, n_head,dk, dv, d_model, hidden_dim,hidden_dropout_prob,attention_probs_dropout_prob, device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention( n_head, dk, dv, d_model,attention_probs_dropout_prob, device)\n",
    "        \n",
    "\n",
    "        self.feedforward = FeedForward(d_model, hidden_dim,hidden_dropout_prob, device)\n",
    "\n",
    "    \n",
    "        self.norm1 =  nn.LayerNorm(d_model,device = device)\n",
    "        self.norm2 = nn.LayerNorm(d_model,device=device)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x =  self.norm1(self.mha(x,x,x)+x)\n",
    "        x = self.norm2(self.feedforward(x)+x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class Bert(nn.Module):\n",
    "    def __init__(self, n_layer, n_head,dk, dv, d_model, hidden_dim, vocab_size,max_seq_len,hidden_dropout_prob,attention_probs_dropout_prob, device = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([BERTLayer(n_head,dk, dv, d_model, hidden_dim,hidden_dropout_prob,attention_probs_dropout_prob, device) for _ in range(n_layer)])\n",
    "        self.n_layer = n_layer\n",
    "        self.tok_embedding = nn.Embedding(vocab_size, d_model, device=device)\n",
    "        self.pos_embedding = nn.Embedding(max_seq_len, d_model, device=device)\n",
    "        self.segment_embedding = nn.Embedding(2, d_model, device=device) \n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def forward(self, x, segment_ids):\n",
    "        batch_size, seq_len = x.size()\n",
    "        positions = torch.arange(0, seq_len, device=self.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "\n",
    "        x = (\n",
    "            self.tok_embedding(x)\n",
    "            + self.pos_embedding(positions)\n",
    "            + self.segment_embedding(segment_ids)\n",
    "        )\n",
    "        for layer in self.layers:\n",
    "            x =  layer(x)\n",
    "\n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "## In the paper of the paper of the BERTbased the hyperparameter where:\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Bert(\n",
    "    n_layer=12,\n",
    "    n_head=12,\n",
    "    dk=64,\n",
    "    dv=64,\n",
    "    d_model=768,\n",
    "    hidden_dim=3072,\n",
    "    vocab_size=30522,\n",
    "    max_seq_len=512,\n",
    "    hidden_dropout_prob = 0.1,\n",
    "    attention_probs_dropout_prob = 0.1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight from huggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weights loaded from HuggingFace into the model!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#load the weight from huggingface\n",
    "hf_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "hf_state_dict = hf_model.state_dict()\n",
    "\n",
    "model.tok_embedding.weight.data.copy_(hf_state_dict['embeddings.word_embeddings.weight'])\n",
    "model.pos_embedding.weight.data.copy_(hf_state_dict['embeddings.position_embeddings.weight'])\n",
    "model.segment_embedding.weight.data.copy_(hf_state_dict['embeddings.token_type_embeddings.weight'])\n",
    "\n",
    "for layer_idx in range(12):\n",
    "    custom_layer = model.layers[layer_idx]\n",
    "    hf_prefix = f'encoder.layer.{layer_idx}'\n",
    "\n",
    "    hf_q = hf_state_dict[f'{hf_prefix}.attention.self.query.weight']\n",
    "    hf_k = hf_state_dict[f'{hf_prefix}.attention.self.key.weight']\n",
    "    hf_v = hf_state_dict[f'{hf_prefix}.attention.self.value.weight']\n",
    "    hf_qb = hf_state_dict[f'{hf_prefix}.attention.self.query.bias']\n",
    "    hf_kb = hf_state_dict[f'{hf_prefix}.attention.self.key.bias']\n",
    "    hf_vb = hf_state_dict[f'{hf_prefix}.attention.self.value.bias']\n",
    "\n",
    "    for head_idx in range(12):\n",
    "        start = head_idx * 64\n",
    "        end = (head_idx + 1) * 64\n",
    "\n",
    "        attn_head = custom_layer.mha.attentions[head_idx]\n",
    "        attn_head.WQ.weight.data.copy_(hf_q[start:end, :])\n",
    "        attn_head.WK.weight.data.copy_(hf_k[start:end, :])\n",
    "        attn_head.WV.weight.data.copy_(hf_v[start:end, :])\n",
    "\n",
    "        attn_head.WQ.bias.data.copy_(hf_qb[start:end])\n",
    "        attn_head.WK.bias.data.copy_(hf_kb[start:end])\n",
    "        attn_head.WV.bias.data.copy_(hf_vb[start:end])\n",
    "\n",
    "    custom_layer.mha.output.weight.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.attention.output.dense.weight']\n",
    "    )\n",
    "    custom_layer.mha.output.bias.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.attention.output.dense.bias']\n",
    "    )\n",
    "\n",
    "    custom_layer.norm1.weight.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.attention.output.LayerNorm.weight']\n",
    "    )\n",
    "    custom_layer.norm1.bias.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.attention.output.LayerNorm.bias']\n",
    "    )\n",
    "\n",
    "    custom_layer.feedforward.ff1.weight.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.intermediate.dense.weight']\n",
    "    )\n",
    "    custom_layer.feedforward.ff1.bias.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.intermediate.dense.bias']\n",
    "    )\n",
    "    custom_layer.feedforward.ff2.weight.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.output.dense.weight']\n",
    "    )\n",
    "    custom_layer.feedforward.ff2.bias.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.output.dense.bias']\n",
    "    )\n",
    "\n",
    "    custom_layer.norm2.weight.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.output.LayerNorm.weight']\n",
    "    )\n",
    "    custom_layer.norm2.bias.data.copy_(\n",
    "        hf_state_dict[f'{hf_prefix}.output.LayerNorm.bias']\n",
    "    )\n",
    "\n",
    "print(\"All weights loaded from HuggingFace into the model!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use our custom bert for embeddings creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "class customBERTEmbedding(Embeddings):\n",
    "    def __init__(self, model, tokenizer, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._encode(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return self._encode(text)\n",
    "    \n",
    "    def _encode(self,text):\n",
    "        tokens = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        input_ids = tokens[\"input_ids\"].to(self.device)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_ids, token_type_ids)\n",
    "        return output[:, 0, :].squeeze(0).cpu().numpy()\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.65726030e-01, -2.13014893e-02, -8.69558901e-02,  1.48365214e-01,\n",
       "        1.76800609e-01, -3.63985479e-01,  4.23639625e-01,  1.46304592e-01,\n",
       "       -5.11988819e-01, -2.00829223e-01, -4.06282097e-01,  4.06917967e-02,\n",
       "       -2.24899203e-01,  1.40499860e-01,  3.65187377e-02,  1.04855657e-01,\n",
       "       -3.56116056e-01,  3.78544360e-01,  1.37843788e-01, -2.61878073e-01,\n",
       "       -8.52976367e-03, -3.59228045e-01, -5.17454684e-01, -2.01545537e-01,\n",
       "       -2.05509856e-01, -3.38057280e-01,  1.83744028e-01,  4.14895236e-01,\n",
       "        6.08539172e-02,  2.84590006e-01, -8.40660259e-02,  4.02905345e-02,\n",
       "        1.19624868e-01, -3.58762801e-01,  1.91606462e-01, -2.62056980e-02,\n",
       "       -1.53285637e-01, -6.93488866e-03, -2.34032542e-01, -8.47237278e-03,\n",
       "        1.14708841e-01,  3.33218277e-02,  4.20786083e-01, -4.48948033e-02,\n",
       "        7.21191093e-02,  3.09038967e-01, -2.34791279e+00,  2.59799254e-03,\n",
       "       -2.70282507e-01,  3.30774561e-02,  5.01673698e-01,  2.88069189e-01,\n",
       "        1.01765446e-01,  1.11193165e-01,  1.71884298e-01,  1.46862641e-01,\n",
       "       -3.50257516e-01,  8.72139513e-01, -4.09970023e-02, -3.04010868e-01,\n",
       "       -7.76922032e-02,  1.13930210e-01, -2.35657454e-01, -3.23152989e-01,\n",
       "        4.15269248e-02, -1.55207021e-02, -2.16269583e-01,  5.31697035e-01,\n",
       "        7.03534633e-02,  8.42131615e-01, -1.81045860e-01, -3.73245656e-01,\n",
       "        3.89892817e-01, -2.94357419e-01,  2.76545696e-02, -3.99857819e-01,\n",
       "        1.72398835e-01, -1.56366676e-01,  7.77730271e-02,  4.94193733e-01,\n",
       "        1.86763048e-01,  2.40592554e-01,  3.03343296e-01, -2.51660757e-02,\n",
       "        5.60638793e-02, -4.96314429e-02, -3.21910530e-01, -3.79916012e-01,\n",
       "       -1.31395847e-01,  5.96993625e-01, -4.16167825e-01,  1.13621704e-01,\n",
       "        4.81570572e-01,  4.27230038e-02,  3.39746416e-01,  2.36948758e-01,\n",
       "       -2.66996384e-01,  1.18479706e-01, -5.12724109e-02, -1.55013070e-01,\n",
       "        1.49984313e-02,  6.18680790e-02,  2.48256743e-01, -1.72768179e-02,\n",
       "        1.81890890e-01,  1.03422023e-01, -1.73140064e-01, -2.40924999e-01,\n",
       "       -9.72500667e-02, -3.47015619e+00, -3.98786068e-02, -3.11250806e-01,\n",
       "       -4.96254593e-01, -2.60028958e-01, -1.36426330e-01,  4.06547427e-01,\n",
       "        3.00078094e-01, -2.24331573e-01,  1.08742006e-01,  4.14652973e-01,\n",
       "       -6.07140958e-01,  2.06456468e-01, -2.19296098e-01, -2.06170045e-02,\n",
       "        9.06831771e-02,  1.24083310e-02, -2.32998822e-02,  1.45791769e-01,\n",
       "        5.15577500e-04,  1.27751142e-01, -1.24387525e-01,  6.77214265e-01,\n",
       "        9.75939706e-02, -1.83886111e-01,  3.14532071e-02,  9.22402143e-02,\n",
       "        3.62644643e-01,  2.30564311e-01, -2.91382909e-01, -9.38628688e-02,\n",
       "       -2.91142523e-01, -1.64423600e-01, -4.13269901e+00,  2.68588245e-01,\n",
       "        4.36905533e-01, -1.56972751e-01,  1.32456690e-01,  3.34203035e-01,\n",
       "       -2.38374949e-01,  7.88845867e-03,  5.50103746e-02,  2.79896319e-01,\n",
       "       -1.00399092e-01, -4.20745350e-02,  3.42639908e-02,  3.17380339e-01,\n",
       "       -3.33679020e-01, -1.24237396e-01,  1.99413627e-01, -1.57790348e-01,\n",
       "        1.01288758e-01, -3.53561372e-01,  1.10977471e-01, -2.87320584e-01,\n",
       "        2.02236161e-01,  5.37658595e-02,  1.74246043e-01,  6.57502532e-01,\n",
       "        4.60059941e-01,  3.06721739e-02, -6.50569260e-01,  1.37021124e-01,\n",
       "       -2.04956755e-01,  1.80636361e-01,  2.92092681e-01, -2.08814204e-01,\n",
       "        1.75481990e-01,  2.75338143e-01,  1.57103524e-01,  2.74149626e-01,\n",
       "        1.29708216e-01, -2.98012868e-02, -1.69484273e-01, -1.16883986e-01,\n",
       "        4.76126134e-01,  3.25952113e-01,  2.39540696e-01, -3.03329945e-01,\n",
       "        3.43712777e-01,  2.20104754e-01,  2.26097584e-01,  3.53757918e-01,\n",
       "        4.06538367e-01,  1.69412419e-01,  3.22517544e-01,  2.43885830e-01,\n",
       "        2.30847839e-02,  7.71313980e-02,  4.21175718e-01,  5.79784214e-01,\n",
       "        2.63905451e-02, -1.62122883e-02,  2.07198218e-01, -2.18859136e-01,\n",
       "       -1.05968513e-01,  3.71062446e+00, -1.38602465e-01, -4.32286412e-01,\n",
       "       -3.03860486e-01,  4.57532644e-01, -2.53390014e-01,  1.75779387e-01,\n",
       "        2.11641505e-01,  2.67255213e-02,  2.26273552e-01, -2.73360461e-01,\n",
       "        1.59019068e-01, -5.72768569e-01, -9.72552970e-02, -1.17219657e-01,\n",
       "        4.20114160e-01,  3.59881759e-01,  5.88729866e-02,  2.11862147e-01,\n",
       "        1.57735899e-01,  6.82855427e-01,  2.12086365e-01,  6.79479897e-01,\n",
       "       -5.84620051e-02, -6.83167517e-01, -3.00520957e-02,  1.14760183e-01,\n",
       "       -5.63592315e-01,  3.78514737e-01, -5.83428204e-01, -6.43623993e-02,\n",
       "        3.37962583e-02, -3.63828540e-01,  3.58657867e-01,  2.14897275e-01,\n",
       "        2.67568499e-01,  5.14366012e-03,  8.26963708e-02, -3.35142702e-01,\n",
       "        5.61119020e-02,  1.89307526e-01,  2.72937529e-02,  1.07621141e-01,\n",
       "        4.02043462e-01, -9.69542637e-02,  6.16644084e-01, -2.55120635e-01,\n",
       "       -1.30765542e-01,  8.34974423e-02, -1.38023421e-02, -2.86464304e-01,\n",
       "        6.16235062e-02, -4.80368435e-02, -4.92831171e-01,  4.44501005e-02,\n",
       "        4.78178561e-02, -1.37724802e-01,  5.70015788e-01, -3.86842191e-01,\n",
       "        2.82012038e-02, -3.22258443e-01, -5.43408468e-02, -6.20948076e-01,\n",
       "        6.93940341e-01,  1.36227489e-01, -5.87138355e-01,  1.28301978e-01,\n",
       "       -6.45844579e-01, -5.76387691e+00,  1.90212071e-01, -2.31539588e-02,\n",
       "        2.17175901e-01, -1.16741350e-02,  3.45212013e-01,  2.05527216e-01,\n",
       "        2.45614037e-01,  2.91743428e-02, -4.47957069e-01,  4.39469039e-01,\n",
       "       -2.74425119e-01, -1.20536992e-02,  1.57419607e-01, -6.75279975e-01,\n",
       "        2.39498708e-02, -2.03437343e-01,  1.16829813e-01,  7.30588287e-02,\n",
       "        1.69199333e-01, -1.11769907e-01,  2.53224462e-01, -3.36820751e-01,\n",
       "        2.64848411e-01,  1.54386342e-01, -3.44297260e-01,  8.36476535e-02,\n",
       "       -2.50043899e-01,  2.37854749e-01, -4.70270306e-01,  1.72967136e-01,\n",
       "       -3.09446633e-01,  1.61190212e-01, -4.24753010e-01, -4.83538568e-01,\n",
       "       -3.37163115e+00, -3.22436422e-01, -6.79607466e-02, -3.59063774e-01,\n",
       "       -1.68800294e-01,  5.77856660e-01,  4.36027110e-01, -9.61257964e-02,\n",
       "       -8.44805777e-01,  1.01959735e-01, -3.04664582e-01,  7.85902888e-02,\n",
       "       -3.48187953e-01,  4.06143963e-01, -7.17324913e-02,  4.19115454e-01,\n",
       "        1.37178794e-01,  1.46101594e-01, -1.00455798e-01,  3.31784248e-01,\n",
       "       -2.42058948e-01, -1.82825089e-01, -3.28373283e-01, -1.21540464e-01,\n",
       "       -4.69289683e-02,  4.78938788e-01, -7.34156817e-02,  1.16058486e-02,\n",
       "       -3.89918864e-01,  1.22185901e-01,  1.90066602e-02, -1.30055040e-01,\n",
       "       -3.67118567e-02, -2.20956486e-02, -5.50905704e-01, -2.59346575e-01,\n",
       "        8.06215927e-02, -2.64710300e-02,  5.67852199e-01, -7.81191662e-02,\n",
       "       -2.98769951e-01,  1.02209890e+00,  3.17989141e-02,  2.62040526e-01,\n",
       "        4.47048724e-01, -1.24442264e-01,  8.33394676e-02, -1.27147183e-01,\n",
       "       -1.65432602e-01,  4.17202190e-02,  3.45457532e-02, -9.67059135e-02,\n",
       "        1.30670059e+00,  1.35813206e-02,  8.16664875e-01,  1.05243027e-01,\n",
       "        3.36861342e-01,  4.66789275e-01,  1.49370525e-02, -2.29034916e-01,\n",
       "        6.85096622e-01,  4.21301723e-01,  5.96070528e-01, -8.65685716e-02,\n",
       "       -2.65977174e-01, -6.52404904e-01,  1.34485960e-01, -5.46999514e-01,\n",
       "        2.18908906e-01,  4.00801659e-01,  1.16181701e-01,  1.86632141e-01,\n",
       "       -1.97725487e-03, -8.42207193e-01, -5.79754591e-01,  1.52258903e-01,\n",
       "       -8.65734696e-01,  1.34242717e-02,  1.39763966e-01, -1.18638553e-01,\n",
       "       -1.71348944e-01, -1.13516718e-01, -2.31561348e-01,  2.95336276e-01,\n",
       "       -5.18983483e-01,  5.03185764e-02,  9.66896191e-02, -1.84509113e-01,\n",
       "       -1.40713975e-01, -1.13062181e-01, -6.93606138e-01,  4.18993622e-01,\n",
       "       -1.93705186e-02,  2.25174487e-01,  1.71055108e-01,  2.46991161e-02,\n",
       "        4.80600715e-01, -8.98597181e-01,  1.58996150e-01, -1.07576944e-01,\n",
       "       -2.56396472e-01, -3.08680296e-01, -2.95060635e-01,  3.54814857e-01,\n",
       "       -3.73352796e-01,  1.67284995e-01, -2.65818059e-01,  7.46677145e-02,\n",
       "        2.86445743e-03,  3.25215161e-01,  3.16543669e-01, -1.45187914e-01,\n",
       "        1.26408720e-02,  1.67930782e-01,  8.16091776e-01,  3.14352274e-01,\n",
       "        2.30908662e-01,  2.37604186e-01,  3.24800223e-01,  2.41270289e-01,\n",
       "       -8.32330287e-02,  3.12780499e-01, -1.15765356e-01, -4.21855599e-02,\n",
       "        7.84836244e-03,  3.88189107e-02,  2.44762719e-01, -6.58536196e-01,\n",
       "       -2.99807519e-01, -2.92841643e-01,  1.12467989e-01,  5.43196984e-02,\n",
       "       -1.45803258e-01, -1.43034115e-01,  1.12907607e-02, -5.06241381e-01,\n",
       "       -4.72825468e-01,  3.11549693e-01, -2.81161696e-01,  2.85446078e-01,\n",
       "        2.70870507e-01, -1.38502523e-01,  9.58904698e-02,  6.85130954e-01,\n",
       "        1.77039653e-01,  6.27707317e-02, -8.89378563e-02, -1.08469009e-01,\n",
       "       -2.19994396e-01,  5.52535951e-01, -9.48573053e-02, -4.67315048e-01,\n",
       "        1.59208458e-02,  3.10919504e-03, -9.33975205e-02, -1.01537950e-01,\n",
       "        6.38439953e-02, -9.05772746e-02,  5.81315951e-03, -5.79496920e-02,\n",
       "        6.67909235e-02, -1.70747712e-01, -1.17944658e+00,  5.07075608e-01,\n",
       "        1.32690579e-01, -5.28478026e-01,  2.63678044e-01,  3.06698114e-01,\n",
       "       -3.08862478e-01,  2.33366624e-01, -2.84602512e-02,  2.15301216e-01,\n",
       "        8.66685063e-02, -3.86419266e-01,  4.91340123e-02, -2.03345180e-01,\n",
       "        2.11411998e-01,  1.50332034e-01,  2.58970171e-01,  5.28115500e-03,\n",
       "       -2.45882884e-01, -1.77075148e-01, -2.60927409e-01,  1.84706479e-01,\n",
       "       -4.42446113e-01, -5.72500050e-01, -9.98031870e-02, -2.64082819e-01,\n",
       "        4.37102504e-02,  6.47586882e-01,  1.01397097e-01,  3.19614649e-01,\n",
       "        2.65994161e-01, -3.35875839e-01, -4.17557627e-01,  1.91080034e-01,\n",
       "        2.68363297e-01,  4.48891111e-02,  1.80117086e-01, -1.32008560e-03,\n",
       "        4.49907511e-01,  2.74057239e-01, -6.78224117e-02,  1.30855784e-01,\n",
       "        9.20665935e-02, -2.56677270e-01,  1.43912807e-01, -8.75256062e-02,\n",
       "       -3.35381269e-01,  3.56935114e-01,  2.25165129e-01, -1.63646504e-01,\n",
       "       -2.69826502e-01, -5.65298140e-01,  8.17003027e-02, -1.80177286e-01,\n",
       "        2.15541631e-01,  2.07754046e-01,  3.44103426e-02, -1.33306339e-01,\n",
       "       -5.44709027e-01,  2.64728427e-01,  1.49861621e-02, -2.76964366e-01,\n",
       "       -1.58228844e-01,  4.27868426e-01, -5.93939841e-01, -5.68741679e-01,\n",
       "       -7.44556785e-02,  1.20060079e-01, -5.34066677e-01,  1.49789035e-01,\n",
       "       -2.25646067e-02,  3.29046585e-02,  3.34141135e-01, -1.10570468e-01,\n",
       "       -8.08419645e-01,  1.29364565e-01,  1.85885325e-01, -1.30569711e-02,\n",
       "        3.95953834e-01, -1.42496929e-01,  2.13077158e-01, -2.40181491e-01,\n",
       "       -2.50419647e-01,  3.79680514e-01,  1.18906004e-02,  3.56537730e-01,\n",
       "       -5.07551804e-02, -2.37539053e-01, -1.53900281e-01,  1.39073342e-01,\n",
       "       -1.34629741e-01, -3.16618115e-01,  4.16127264e-01, -8.98781642e-02,\n",
       "        3.99991363e-01,  1.98406741e-01,  6.58637509e-02,  4.03114676e-01,\n",
       "       -1.56529143e-01,  1.24869972e-01,  1.53808311e-01,  4.44098830e-01,\n",
       "        5.01755536e-01,  1.70465663e-01, -4.42709833e-01, -2.71177202e-01,\n",
       "        6.16666555e-01,  2.62676269e-01, -3.05585843e-02,  2.58293629e-01,\n",
       "       -3.05484533e-01,  2.20666364e-01, -6.73248470e-02,  9.95890126e-02,\n",
       "       -1.85327843e-01, -4.39110175e-02, -1.72674283e-01, -2.25969166e-01,\n",
       "        3.21754813e+00,  3.50482017e-01, -2.12835371e-01, -3.53619754e-02,\n",
       "        1.77591905e-01,  3.70894633e-02, -4.58226472e-01,  8.86629000e-02,\n",
       "       -3.08702976e-01,  3.30107421e-01,  2.27546945e-01, -1.54253766e-01,\n",
       "        1.24139115e-01, -1.73012197e-01,  3.64007115e-01,  7.09351361e-01,\n",
       "       -7.16223478e-01, -9.82089341e-02, -1.19720185e+00,  2.50691742e-01,\n",
       "       -2.91052043e-01,  6.05815053e-01,  1.94381461e-01,  3.07783931e-01,\n",
       "        5.71685076e-01,  5.45236230e-01, -2.02006027e-01, -2.53586233e-01,\n",
       "       -4.79833931e-02,  2.19518598e-02, -2.13130474e-01,  3.35140854e-01,\n",
       "        2.17550635e-01,  2.72899121e-01,  1.36939716e-02,  2.86378741e-01,\n",
       "        8.92856196e-02, -5.38212597e-01,  1.48358308e-02,  8.18953440e-02,\n",
       "        1.21889748e-01,  1.28781404e-02,  6.99469447e-01,  1.51976109e-01,\n",
       "       -2.68097699e-01,  6.90416157e-01, -2.00848088e-01, -6.65243983e-01,\n",
       "        1.17335185e-01, -2.38500275e-02,  1.05166137e-01, -1.10356867e-01,\n",
       "       -4.59202915e-01,  1.30043313e-01, -1.23176448e-01, -1.38595209e-01,\n",
       "       -4.37621847e-02, -5.92441158e-03, -1.47283509e-01,  3.37422311e-01,\n",
       "        2.42893100e-01,  5.64224795e-02,  1.30608365e-01, -1.21438079e-01,\n",
       "        9.76651311e-02, -4.84313583e-03, -4.13556457e-01,  9.58470721e-03,\n",
       "        5.61921299e-02, -2.99825847e-01,  1.44959882e-01,  2.31456608e-01,\n",
       "        8.26427937e-02,  6.84511065e-02, -2.22194120e-02, -1.09754585e-01,\n",
       "        6.79693557e-03, -8.86346176e-02, -9.74337459e-02, -4.30790758e+00,\n",
       "       -1.44564077e-01,  7.17882812e-02,  2.84603238e-01,  2.42797554e-01,\n",
       "        6.93099350e-02,  1.04170993e-01,  1.12106718e-01,  3.67973149e-01,\n",
       "       -7.56559744e-02,  2.88751125e-01,  3.24402988e-01, -1.52865043e-02,\n",
       "       -1.35207608e-01, -2.35874251e-01,  4.33269024e-01,  5.18153496e-02,\n",
       "       -8.62458944e-01,  1.42681211e-01, -3.39763850e-01, -3.19392949e-01,\n",
       "       -1.46972522e-01, -3.61375540e-01, -2.95002423e-02, -6.34716824e-02,\n",
       "        8.10889959e-01, -4.66546556e-03, -5.59613883e-01, -1.38490230e-01,\n",
       "        1.08803198e-01, -2.12249607e-01,  3.56190890e-01,  2.19504088e-01,\n",
       "        3.29702318e-01, -1.91675704e-02, -4.48283851e-01, -1.05795257e-01,\n",
       "       -1.78183876e-02,  1.85253829e-01,  1.71124950e-01, -4.28314507e-01,\n",
       "        3.38014841e-01,  1.17351241e-01,  3.04146200e-01, -3.22614938e-01,\n",
       "       -2.49624729e-01,  3.77065867e-01, -5.55732191e-01,  3.40959221e-01,\n",
       "       -3.05481195e-01, -3.71931046e-01,  2.05917090e-01, -1.21029802e-01,\n",
       "        3.14698182e-02,  2.80687928e-01, -1.90525502e-02, -2.39811003e-01,\n",
       "        1.49949864e-01, -2.97779411e-01,  6.63799420e-02, -2.36271232e-01,\n",
       "       -2.01111101e-02,  1.39183298e-01,  2.13334933e-01,  2.77518839e-01,\n",
       "       -5.22739053e-01,  4.67542522e-02, -3.64431739e-02, -1.89457864e-01,\n",
       "        2.90222704e-01,  1.48728624e-01, -2.47858148e-02,  4.49920684e-01,\n",
       "        1.75790191e-01,  2.11248696e-01,  1.22359388e-01,  2.70287633e-01,\n",
       "        3.51397783e-01, -3.04126710e-01,  2.02848185e-02,  3.83384258e-01,\n",
       "       -3.60808074e-01, -2.41613790e-01,  1.79748356e-01,  2.07440630e-02,\n",
       "       -2.93750197e-01, -4.83513445e-01, -2.44219542e-01,  1.14409387e-01,\n",
       "       -1.96039900e-01, -2.01193884e-01,  1.46204263e-01, -2.23392304e-02,\n",
       "        2.52505224e-02, -2.14451760e-01,  6.65132515e-03,  1.24089204e-01,\n",
       "       -2.69662231e-01, -5.35178669e-02,  2.01853186e-01,  4.76183593e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer =  BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text =\"i like\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "with torch.no_grad():\n",
    "    a= model(tokens['input_ids'].to(device),tokens['token_type_ids'].to(device))\n",
    "\n",
    "a[:, 0, :].squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data : Question answer from standford and build the vector data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lataw\\anaconda3\\envs\\vectorization\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lataw\\.cache\\huggingface\\hub\\datasets--squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 912889.02 examples/s]\n",
      "Generating validation split: 100%|██████████| 10570/10570 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad\")\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#Load tokenizer from Huggingface\n",
    "tokenizer =  BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#Instantiate the custom Embedding using our Bert model\n",
    "\n",
    "custom_embedding = customBERTEmbedding(model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "#retreive the data context from our data and create our vector database with chroma db\n",
    "# this can take a lot of time\n",
    "contexts = list(set([item['context'] for item in dataset['train']]))\n",
    "db = Chroma.from_texts(contexts, embedding=custom_embedding, persist_directory=\"./chroma_db\",)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now build the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache_resource\n",
    "def load_generator():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=128,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.5\n",
    "    )\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 20:39:20.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 20:39:20.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 20:39:20.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 20:39:20.714 Thread 'Thread-360': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 20:39:20.717 Thread 'Thread-360': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Device set to use cuda:0\n",
      "2025-03-23 20:39:24.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 20:39:24.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Use the following pieces of context to answer the question at the end. If you don\\'t know the answer to the question, just say that you do not know, don\\'t try to make up an answer, and if you do know, please tell us the answer, not the answer you think you know, and don\\'t tell us what you think is wrong with the answer.If you\\'re not sure, ask your parents.In the U.S. News & World Report\\'s \"America’s Best Colleges\" 2016 issue, Kansas State University was ranked tied for 90th among national universities.=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm = load_generator()\n",
    "\n",
    "# Build the RAG Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "query =\"What is the capital of France?\"\n",
    "qa_chain.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
